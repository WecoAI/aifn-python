{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#_1","title":"About","text":"<p>A client facing API for interacting with the Weco AI's AI function platform. It empowers you to go from zero to AI in just a few seconds!</p> <p>Use this API to build complex AI features fast. We lower the barrier of entry to AI features by providing an interface to prototype solutions quickly, in just a few lines of code and in natural language.</p>"},{"location":"#what_we_offer","title":"What We Offer","text":"<ul> <li>Structured Output (outputs are Python dictionaries that always follow your AI functions JSON schema)</li> <li>Multimodal (language &amp; vision)</li> <li>Grounding (Access to the web)</li> <li>Interpretable (observe reasoning behind outputs)</li> <li>Batched Inputs (have inputs be processed in concurrently)</li> <li>Sync-Async Duality (functions can be both synchronous &amp; asynchronous)</li> </ul>"},{"location":"#getting_started","title":"Getting Started","text":"<p>Install the <code>aifn</code> package: <pre><code>pip install aifn\n</code></pre></p> <p>When using the Weco API, you will need to set the API key: You can find/create your API key here. Once you have your API key, you can pass it directly to our core functions and classes using the <code>api_key</code> argument or set it as an environment variable as shown: <pre><code>export WECO_API_KEY=&lt;YOUR_WECO_API_KEY&gt;\n</code></pre></p>"},{"location":"#example","title":"Example","text":"<p>We created a function on our platform for the following task:</p> <p>\"Analyze a business idea and provide a well reasoned evaluation. Return 'viability_score' (0-100), 'strengths' (list), 'weaknesses' (list), and 'next_steps' (list).\"</p> <p>Here's how you can use this function anywhere in your code! <pre><code>from aifn import AIFunction\nidea_evaluator = AIFunction(\"BusinessIdeaAnalyzer-XYZ123\") # Replace with your actual function name\nresponse = idea_evaluator(\"A subscription service for personalized, AI-generated bedtime stories for children.\").output\n</code></pre></p> <p>To learn how to get the most your of your AI functions, check out our cookbook, our API reference and these end-to-end examples.</p> <p>Happy building!</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We value your contributions! If you believe you can help to improve our package enabling people to build AI with AI, please contribute!</p> <p>Use the following steps as a guideline to help you make contributions:</p> <ol> <li> <p>Download and install package from source:    <pre><code>git clone https://github.com/WecoAI/aifn-python.git\ncd aifn-python\npip install -e \".[dev,docs]\"\n</code></pre></p> </li> <li> <p>Create a new branch for your feature or bugfix:    <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make your changes and run tests to ensure everything is working:</p> <p>Tests can be expensive to run as they make LLM requests with the API key being used so it is the developers best interests to write small and simple tests that adds coverage for a large portion of the package.</p> <p><pre><code>pytest -n auto tests\n</code></pre>   If you're just making changes to the docs, feel free to skip this step.</p> </li> <li> <p>Commit and push your changes, then open a PR for us to view \ud83d\ude01</p> </li> </ol> <p>Please ensure your code follows our style guidelines (Numpy docstrings) and includes appropriate tests. We appreciate your contributions!</p>"},{"location":"api/api/","title":"API Reference","text":""},{"location":"api/api/#aifn.function.AIFunction","title":"AIFunction","text":"<pre><code>AIFunction(\n    fn_name,\n    version=-1,\n    fn_desc=\"\",\n    is_async=False,\n    api_key=None,\n)\n</code></pre> <p>An AI powered function that can be called like any other function to perform a specific task. Driven by foundation models at its core, it can be used to perform a wide range of tasks such as text generation, summarization, translation, visual reasoning, etc. It can be used in both synchronous and asynchronous modes to suit the needs of the user. It also supports multimodal inputs and batch processing for handling multiple inputs at once. To take advantage of the full capabilities of the AI function, it is recommended to use the Weco AI platform to unlock features such as model selection, grounding through web search and more.</p> <p>Retrieve an AI function with its unique name and version.</p> <p>Parameters:</p> Name Type Description Default <code>fn_name</code> <code>str</code> <p>The name of the AI function.</p> required <code>version</code> <code>Union[str, int]</code> <p>The version of the AI function. Defaults to -1, indicating the latest version.</p> <code>-1</code> <code>fn_desc</code> <code>str</code> <p>A description of the AI function. Defaults to an empty string.</p> <code>''</code> <code>is_async</code> <code>bool</code> <p>Indicates whether the function should be asynchronous. Defaults to False.</p> <code>False</code> <code>api_key</code> <code>str</code> <p>The API key for accessing the client. If not provided, it must be set using the environment variable - <code>WECO_API_KEY</code>.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from aifn import AIFunction\n&gt;&gt;&gt; idea_evaluator = AIFunction(\"BusinessIdeaAnalyzer-XYZ123\")\n</code></pre>"},{"location":"api/api/#aifn.function.AIFunction.__call__","title":"__call__","text":"<pre><code>__call__(\n    text_input=\"\",\n    images_input=[],\n    return_reasoning=False,\n    strict=False,\n)\n</code></pre> <p>Call the AI function with the provided inputs.</p> <p>Parameters:</p> Name Type Description Default <code>text_input</code> <code>str</code> <p>The text input to the function. Defaults to an empty string.</p> <code>''</code> <code>images_input</code> <code>List[str]</code> <p>A list of image URLs or base64 encoded images to be used as input to the function. Defaults to an empty list.</p> <code>[]</code> <code>return_reasoning</code> <code>bool</code> <p>If True, includes reasoning in the response. Defaults to False.</p> <code>False</code> <code>strict</code> <code>bool</code> <p>A flag to indicate if the function should be queried in strict mode. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>NamedTuple</code> <p>A NamedTuple containing the output and metadata of the response.</p> <p>Examples:</p> <p>Build and call a function</p> <pre><code>&gt;&gt;&gt; from aifn import build\n&gt;&gt;&gt; country_to_capital = build(\"Given a country name, return its capital city as 'capital'.\")\n&gt;&gt;&gt; response = country_to_capital(\"France\")\n&gt;&gt;&gt; response.output[\"capital\"]\n'Paris'\n</code></pre> <p>Retrieve and call an existing function</p> <pre><code>&gt;&gt;&gt; from aifn import AIFunction\n&gt;&gt;&gt; idea_evaluator = AIFunction(\"BusinessIdeaAnalyzer-XYZ123\")\n&gt;&gt;&gt; response = idea_evaluator(\"A platform to connect pet owners with pet sitters.\")\n&gt;&gt;&gt; response.output[\"score\"]\n0.85\n</code></pre> <p>Call an existing function with image inputs</p> <pre><code>&gt;&gt;&gt; from aifn import AIFunction\n&gt;&gt;&gt; image_classifier = AIFunction(\"ImageClassifier-ABC123\")\n&gt;&gt;&gt; response = image_classifier(images_input=[\"https://example.com/cat.jpg\"])\n&gt;&gt;&gt; response.output[\"label\"]\n'cat'\n</code></pre>"},{"location":"api/api/#aifn.function.AIFunction.batch","title":"batch","text":"<pre><code>batch(\n    batch_inputs=[], return_reasoning=False, strict=False\n)\n</code></pre> <p>Call the AI function in batch mode with the provided inputs.</p> <p>Parameters:</p> Name Type Description Default <code>batch_inputs</code> <code>List[Dict[str, Any]]</code> <p>A list of input dictionaries for the function. Each dictionary can include: - \"text_input\": A string for text input. - \"images_input\": A list of image URLs or base64 encoded images.</p> <code>[]</code> <code>return_reasoning</code> <code>bool</code> <p>If True, includes reasoning in the response. Defaults to False.</p> <code>False</code> <code>strict</code> <code>bool</code> <p>A flag to indicate if the function should be queried in strict mode. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[NamedTuple]</code> <p>A list of NamedTuples, each containing the output and metadata of the response.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from aifn import build\n&gt;&gt;&gt; country_to_capital = build(\"Given a country name, return its capital city as 'capital'.\")\n&gt;&gt;&gt; batch_inputs = [{\"text_input\": \"India\"}, {\"text_input\": \"USA\"}, {\"text_input\": \"UK\"}]\n&gt;&gt;&gt; responses = country_to_capital.batch(batch_inputs)\n&gt;&gt;&gt; outputs = [response.output[\"capital\"] for response in responses]\n&gt;&gt;&gt; outputs\n['New Delhi', 'Washington, D.C.', 'London']\n</code></pre>"},{"location":"api/api/#aifn.function.AIFunction.make_sync","title":"make_sync","text":"<pre><code>make_sync()\n</code></pre> <p>Convert an asynchronous AI function to a synchronous AI Function.</p> <p>Returns:</p> Type Description <code>AIFunction</code> <p>A new AIFunction instance in synchronous mode.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from aifn import build\n&gt;&gt;&gt; country_to_capital = build(\"Given a country name, return its capital city as 'capital'.\", is_async=True)\n&gt;&gt;&gt; sync_country_to_capital = country_to_capital.make_sync()\n&gt;&gt;&gt; response = sync_country_to_capital(\"USA\")\n&gt;&gt;&gt; response.output[\"capital\"]\n'Washington, D.C.'\n</code></pre>"},{"location":"api/api/#aifn.function.AIFunction.make_async","title":"make_async","text":"<pre><code>make_async()\n</code></pre> <p>Convert a synchronous AI function to an asynchronous AI Function.</p> <p>Returns:</p> Type Description <code>AIFunction</code> <p>A new AIFunction instance in asynchronous mode.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from aifn import build\n&gt;&gt;&gt; country_to_capital = build(\"Given a country name, return its capital city as 'capital'.\", is_async=False)\n&gt;&gt;&gt; async_country_to_capital = country_to_capital.make_async()\n&gt;&gt;&gt; response = await async_country_to_capital(\"USA\")\n&gt;&gt;&gt; response.output[\"capital\"]\n'Washington, D.C.'\n</code></pre>"},{"location":"api/api/#aifn.function.build","title":"build","text":"<pre><code>build(task_description, is_async=False, api_key=None)\n</code></pre> <p>Build a specialized AI function for a given task.</p> <p>Parameters:</p> Name Type Description Default <code>task_description</code> <code>str</code> <p>The description of the task for which the function is being built.</p> required <code>is_async</code> <code>bool</code> <p>Indicates whether the function should be asynchronous. Defaults to False.</p> <code>False</code> <code>api_key</code> <code>str</code> <p>The API key for the WecoAI service. If not provided, the API key must be set using the environment variable - <code>WECO_API_KEY</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>AIFunction</code> <p>A specialized AI function for the given task.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from aifn import build\n&gt;&gt;&gt; country_to_capital = build(\"Given a country name, return its capital city as 'capital'.\")\n&gt;&gt;&gt; country_to_capital(\"India\").output[\"capital\"]\n'New Delhi'\n</code></pre>"},{"location":"cookbook/cookbook/","title":"Cookbook","text":""},{"location":"cookbook/cookbook/#getting_started","title":"Getting Started","text":"<p>A client facing API for interacting with the Weco AI's AI function platform. It empowers you to go from zero to AI in just a few seconds!</p> <p>Here are a few features our users often ask about. Feel free to follow along:</p> <p> </p> <pre><code># Install the package\n%pip install aifn\n</code></pre> <p>You can find/setup your API key here.</p> <pre><code>import os\nos.environ[\"WECO_API_KEY\"] = \"YOUR_WECO_API_KEY\"\n</code></pre> <p>You can build powerful AI functions for complex tasks quickly and without friction. For example, you can create an AI function on our platform with a simple description as shown below:</p> <p>\"Analyze a business idea and provide a well reasoned evaluation. Return 'viability_score' (0-100), 'strengths' (list), 'weaknesses' (list), and 'next_steps' (list).\"</p> <p>Once the function has been built, you can call, test and deploy it anywhere in your code with just three lines of code:</p> <pre><code>from aifn import AIFunction\n\nidea_evaluator = AIFunction(\"BusinessIdeaAnalyzer-XYZ123\") # Replace with your actual function name\n\nresponse = idea_evaluator(\"A subscription service for personalized, AI-generated bedtime stories for children.\").output\nprint(response)\n</code></pre>"},{"location":"cookbook/cookbook/#structured_output","title":"Structured Output","text":"<p>There is a 100% guarantee of a structured output on an function call! This means that you can pass any unstructured input in and get back a valid structured output that follows the JSON schema optimally determined by the AI function for your task. You can also edit, write and replace the JSON schema for an AI function on our platform.</p> <p>Here's an example where we extract relevant information about the different object in this image:</p> <p></p> <pre><code>from aifn import build\n\ninformation_extractor = build(\"Describe the unique set of the objects present in the image. Provide the 'object', a 'description' and 'count' of how many times that particular object appeared in the image.\")\n\n# You may be wondering what the metadata here is. We'll get to that in a second.\nobject_dict, metadata = information_extractor(images_input=[\"https://us.images.westend61.de/0001348304i/directly-above-shot-of-various-objects-on-table-EYF01650.jpg\"])\nfor object in object_dict['objects']:\n    print(f\"{object['object']}: {object['description']} (appeared {object['count']} times)\")\n</code></pre>"},{"location":"cookbook/cookbook/#ai_function_and_function_response_metadata","title":"AI Function and Function Response Metadata","text":"<p>We do recommend building AI functions on our platform to prototype faster and achieve the right balance between speed, intelligence and cost. Here's how you can find the AI function we built in the previous example on the platform. Simply extract the function name, and use it to find the corresponding AI function on the platform. If you need to know the exact version, you can extract that from the <code>AIFunction</code> class as well to find the exact version being used.</p> <pre><code>fn_name = information_extractor.fn_name\nprint(f\"Function name: {fn_name}\")\nversion = information_extractor.version\nprint(f\"Version: {version}\")\n</code></pre> <p>If you're a developer and you want to use AI powered functions, you probably care about things like the input and output token counts and the latency of the AI function. Its easily accessible! Let's look at how we can get this information for the previous function call.</p> <pre><code>n_input_tokens = metadata[\"in_tokens\"]\nn_output_tokens = metadata[\"out_tokens\"]\nlatency_milliseconds = metadata[\"latency_ms\"]\nprint(f\"Input tokens: {n_input_tokens}, Output tokens: {n_output_tokens}, Latency: {latency_milliseconds}ms\")\n</code></pre>"},{"location":"cookbook/cookbook/#sync-async_duality","title":"Sync-Async Duality","text":"<p>AI Functions can be made to be both synchronous or asynchronous functions, allowing for more flexible use.</p> <pre><code>from aifn import build\n\n# Build an synchronous function\ntranslator = build(\"Return the 'translation' of english to french.\")\ntranslation = translator(\"Hello, how are you?\").output['translation']\nprint(translation)\n\n# Make it asynchronous\nasync_translator = translator.make_async()\noutput, metadata = await async_translator(\"Hello, how are you?\")\nprint(output['translation'])\n\n# Build an asynchronous function\ntranslator = build(\"Return the 'translation' of english to french.\", is_async=True)\noutput, metadata = await translator(\"Hello, how are you?\")\nprint(output['translation'])\n\n# Make it synchronous\nsync_translator = translator.make_sync()\ntranslation = sync_translator(\"Hello, how are you?\").output['translation']\nprint(translation)\n</code></pre>"},{"location":"cookbook/cookbook/#batching","title":"Batching","text":"<p>In the previous examples, we've shown you how to call an AI function with just one input. We understand that sometimes you want to submit a large batch of inputs to be processed in concurrently. Every AI function, whether synchronous or asynchronous, can perform batch processing.</p> <pre><code>task_evaluator = build(task_description=\"I want to know if AI can solve a problem for me, how easy it is to arrive at a solution and whether any helpful tips for me along the way. Help me understand this through - 'feasibility', 'justification', and 'suggestions'.\")\n\ntask1 = {\n    \"text_input\": \"I want to train a model to predict house prices using the Boston Housing dataset hosted on Kaggle.\"\n}\ntask2 = {\n    \"text_input\": \"I want to train a model to classify digits using the MNIST dataset hosted on Kaggle using a Google Colab notebook. Attached is an example of what some of the digits would look like.\",\n}\nresponses = task_evaluator.batch([task1, task2])\nfor response in responses:\n    print(\"=\" * 50)\n    print(response.output)\n    print(\"=\" * 50)\n</code></pre>"},{"location":"cookbook/cookbook/#multimodality","title":"Multimodality","text":"<p>Our AI functions can interpret complex visual information, follow instructions in natural language and provide practical insights. We accept a variety of different forms of image input: 1. Base64 encoding 2. Publically available URL 3. Local image path</p> <p>Let's explore how we can have an AI function manage a part of our household. By running this once a month, I am able to find ways to cut down my energy consumption and ultimately save me money!</p> <pre><code>import base64\n\ntask_description = \"\"\"\nYou are a smart home energy analyzer that can process images of smart meters, home exteriors, \nand indoor spaces to provide energy efficiency insights. The analyzer should:\n    1. Interpret smart meter readings\n    2. Assess home features relevant to energy consumption\n    3. Analyze thermostat settings\n    4. Provide energy-saving recommendations\n    5. Evaluate renewable energy potential\n\nThe output should include:\n    - 'energy_consumption': current usage and comparison to average\n    - 'home_analysis': visible energy features and potential issues\n    - 'thermostat_settings': current settings and recommendations\n    - 'energy_saving_recommendations': actionable suggestions with estimated savings\n    - 'renewable_energy_potential': assessment of current and potential renewable energy use\n    - 'estimated_carbon_footprint': current footprint and potential reduction\n\"\"\"\n\nenergy_analyzer = build(task_description=task_description)\n\nrequest = \"\"\"\nAnalyze these images of my home and smart meter to provide energy efficiency insights \nand recommendations for reducing my electricity consumption.\n\"\"\"\n\n# Base64 encoded image\nwith open(\"/path/to/home_exterior.jpeg\", \"rb\") as img_file:\n    my_home_exterior = base64.b64encode(img_file.read()).decode('utf-8')\n\nanalysis = energy_analyzer(\n    text_input=request,\n    images_input=[\n        \"https://example.com/my_smart_meter_reading.png\",  # Public URL\n        f\"data:image/jpeg;base64,{my_home_exterior}\",      # Base64 encoding\n        \"/path/to/living_room_thermostat.jpg\"              # Local image path\n    ]\n).output\n\nfor key, value in analysis.items(): print(f\"{key}: {value}\")\n</code></pre>"},{"location":"cookbook/cookbook/#grounding_via_access_to_the_web","title":"Grounding via Access to the Web","text":"<p>Some of our models even have access to the web. Here's a complete list of models that do:</p> Model Name Provider gemini-1.5-pro-002-online Google gemini-1.5-flash-002-online Google llama-3.1-sonar-huge-128k-online Perplexity llama-3.1-sonar-large-128k-online Perplexity llama-3.1-sonar-small-128k-online Perplexity <p>To enable this, you need to the Settings menu of the specific function and select one of the above as the model to use. After, that simply change the <code>version</code> to the latest version or pass \\(-1\\) when retrieving the <code>AIFunction</code> and deploy your code to production! An even easier way when deploying your code to production is to pass a particular alias that you set for the function version on our platform. This way, whenever you want to switch to a particular function version, you just need to set the alias on our platform and it will automatically be deployed to your production code!</p> <p>If your AI function has access to the web, it opens up a whole new way to ground your model outputs in every day events such as the stock market, current news and more!</p>"},{"location":"cookbook/cookbook/#interpretability","title":"Interpretability","text":"<p>You can now understand why a model generated an output. For this, you'll need to enable Chain of Thought (CoT) for the function version on the platform. You can find this under the Settings for a particular function version. Then, to view the model's reasoning behind an output, simply use <code>return_reasoning=True</code> when you call the function on an input! This can be done for both synchronous and asynchronous and can be be done with the batched inputs as well. The reasoning behind the output can be found in the <code>.metadata[\"reasoning_steps\"]</code> attribute of the function response.</p> <pre><code>task_evaluator = build(task_description=\"I want to know if AI can solve a problem for me, how easy it is to arrive at a solution and whether any helpful tips for me along the way. Help me understand this through - 'feasibility', 'justification', and 'suggestions'.\")\n\noutput, metadata = task_evaluator(\"I want to train a model to predict house prices using the Boston Housing dataset hosted on Kaggle.\", return_reasoning=True)\nfor key, value in output.items(): print(f\"{key}: {value}\")\nfor i, step in enumerate(metadata[\"reasoning_steps\"]): print(f\"Step {i+1}: {step}\")\n</code></pre>"},{"location":"cookbook/cookbook/#end-to-end_examples","title":"End-to-End Examples","text":"<p>For more on what AI functions can do, check out these examples.</p>"},{"location":"cookbook/examples/maze_runner/","title":"Maze Runner","text":"<p>AI functions can navigate mazes</p> <p>In this tutorial, we're going to walk you through how AI functions can interact with games using simply images from the game. To do this, we will use OpenAI's Procgen Benchmark, specifically the 2D maze environment and AI functions by Weco. We'll build an agent that uses AI functions at it's core. Lets jump right in!</p> <p>You can follow along through the code and also watch our quick demo on the same here.</p> <p> </p>"},{"location":"cookbook/examples/maze_runner/#dependencies","title":"Dependencies","text":"<pre><code>%%capture\n!apt-get update -qq\n!apt-get install -y software-properties-common\n!add-apt-repository ppa:openjdk-r/ppa -y\n!apt-get update -qq\n!apt-get install -y xvfb python3-opengl ffmpeg\n!pip install --no-cache-dir aifn Pillow gym procgen pyvirtualdisplay\n</code></pre> <pre><code>import io\nfrom datetime import datetime\nimport base64\nfrom copy import deepcopy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom IPython.display import clear_output\nfrom pyvirtualdisplay import Display\nfrom procgen import ProcgenEnv\nfrom aifn import AIFunction\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n</code></pre>"},{"location":"cookbook/examples/maze_runner/#setup_game","title":"Setup Game","text":"<pre><code>def show_frame(observation, log_history):\n    \"\"\"Helper function to display the current frame and command log.\"\"\"\n    clear_output(wait=True)\n    fig = plt.figure(figsize=(10, 7))\n    gs = fig.add_gridspec(1, 2, width_ratios=[3, 1])\n    ax_left = fig.add_subplot(gs[0])\n    ax_left.imshow(observation['rgb'][0])\n    ax_left.axis('off')\n    ax_right = fig.add_subplot(gs[1])\n    ax_right.axis('off')\n    ax_right.set_facecolor('#f7f7f7')\n    ax_right.set_title(\"Command Log\", loc='center', fontsize=12, pad=10, color='black')\n    log_text = \"\\n\".join(\"&gt; \" + s for s in log_history)\n    ax_right.text(0, 1, log_text, ha='left', va='top', fontsize=10, family='monospace', color='black', wrap=True)\n    plt.tight_layout()\n    plt.show()\n</code></pre> <pre><code>%%capture\ndisplay = Display(visible=0, size=(1400, 900))\ndisplay.start()\n</code></pre> <pre><code># Create our game environment\nenv = ProcgenEnv(num_levels=1, start_level=20, use_backgrounds=False, distribution_mode=\"easy\", num_envs=1, env_name=\"maze\")\n</code></pre>"},{"location":"cookbook/examples/maze_runner/#build_agent","title":"Build Agent","text":"<p>First, head on over to our platform and create an AI function with the following description:</p> <p>You are a grey blob navigating a treacherous 2D maze. Your only way out is to follow the dark road that leads to the orange exit. Return an 'action' that follows the path leading to the exit. Use 1 for left, 7 for right, 5 for up and 3 for down.</p> <p></p> <p>Then grab the function name and come right back here to bring your agent to life!</p> <p></p> <p>We now define a class that uses an AI function at it's very core. The agent here is a simple wrapper around our AI function to provide a more agentic like interface for the game we are about to play. The core function takes in an observation (image), preprocesses this image and passes it to our AI function. The AI function then analyzes the image and returns a simple response. We can then extract and perform the action based on the AI function's judgement.</p> <pre><code>class Agent:\n    def __init__(self, fn_name, api_key):\n        # Initialize your AI function\n        self.get_action = AIFunction(fn_name=fn_name, api_key=api_key)\n\n    def __repr__(self): return str(self.get_action)\n    def __str__(self): return str(self.get_action)\n\n    def act(self, observation):\n        # Preprocess the observation\n        resized_image = Image.fromarray(deepcopy(observation)['rgb'][0].astype(np.uint8)).resize((1024, 1024))\n        buffer = io.BytesIO()\n        resized_image.save(buffer, format=\"jpeg\")\n        images = [f\"data:image/jpeg;base64,{base64.b64encode(buffer.getvalue()).decode('utf-8')}\"]\n        action = self.get_action(images_input=images).output[\"action\"]\n        return action\n\n    def action_to_command(self, action):\n        action_space = {1: \"left\", 7: \"right\", 5: \"up\", 3: \"down\"}\n        return action_space.get(action, \"unknown\")\n</code></pre> <pre><code># NOTE: Don't forget to set these!\napi_key = \"YOUR_API_KEY\"\nfn_name = \"YOUR_AI_FUNCTION_NAME\"\n\n# Initialize our agent that uses an AI function as its brain\nagent = Agent(fn_name, api_key)\nprint(f\"Agent {agent} is on the job!\")\n</code></pre>"},{"location":"cookbook/examples/maze_runner/#play_the_game","title":"Play the Game!","text":"<p>Now you're ready to play the game!</p> <pre><code># We'll give the agent 20 timesteps to navigate the maze but you could give it more if you'd like\ntimesteps = 20\nobservation = env.reset()\n\nlog_history = [f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Agent started navigating the maze\"]\nshow_frame(observation, log_history)\n\nfound = False  # Did the agent find the exit yet?\nwhile timesteps &gt; 0:\n    # Determine the agent's next move based on the current state of the environment\n    action = agent.act(observation)\n    # Observe the results of the agent's action by getting the new state of the environment\n    observation, _, done, _ = env.step(np.array([action]))\n    timesteps -= 1\n\n    log_history.append(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Agent says move {agent.action_to_command(action)}.\")\n    show_frame(observation, log_history)\n\n    if done[0]:\n        # The agent found the exit!\n        found = True\n        break\n\nlog_history.append(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Agent found the exit!\" if found else f\"Agent did not find the exit.\")\nshow_frame(observation, log_history)\n</code></pre> <pre><code>%%capture\nenv.close()\ndisplay.stop()\n</code></pre>"},{"location":"getting_started/installation/","title":"Installation","text":"<p>The package is easy to install and keep up to date.</p>"},{"location":"getting_started/installation/#pip","title":"Pip \ud83d\udce6","text":"<p>Install <code>aifn</code> using <code>pip</code>: <pre><code>pip install aifn\n</code></pre> We always recommend installing the package within a python virtual environment or conda environment.</p> <p>If you already have the package and simply want to upgrade: <pre><code>pip install --upgrade aifn\n</code></pre></p>"},{"location":"getting_started/installation/#source","title":"Source \ud83d\udcd6","text":"<p>You can also install from <code>source</code>: <pre><code>git clone https://github.com/WecoAI/aifn-python\ncd aifn-python\npython install -e .\n</code></pre></p> <p>To upgrade the package to the latest version from <code>source</code>, you can run the following commands: <pre><code>cd aifn-python\ngit pull origin main\npython install -e .\n</code></pre></p>"},{"location":"getting_started/installation/#jump_in","title":"Jump In \ud83c\udfca\u200d\u2642\ufe0f","text":"<p>If you need help getting started, you can check out any of the following resources we provide:</p> <ul> <li>Introduction</li> <li>Cookbook</li> <li>API Reference</li> <li>End-to-End Examples</li> </ul> <p>Happy building!</p>"},{"location":"getting_started/introduction/","title":"Introduction","text":"<p>Lets jump right in!</p>"},{"location":"getting_started/introduction/#export_api_key","title":"Export API Key","text":"<p>When using the Weco API, you will need to set the API key. You can find/setup your API key here. Here's what it looks like.</p> <p></p> <p>Once you have your API key, pass it directly to our <code>build</code> function or <code>AIFunction</code> class (don't worry, we'll cover these shortly) using the <code>api_key</code> argument or set it as an environment variable as shown below: <pre><code>export WECO_API_KEY=&lt;YOUR_WECO_API_KEY&gt;\n</code></pre></p>"},{"location":"getting_started/introduction/#build_deploy","title":"Build &amp; Deploy","text":"<p>We can create a function on the Weco AI platform for the following task:</p> <p>\"Analyze a business idea and provide a well reasoned evaluation. Return 'viability_score' (0-100), 'strengths' (list), 'weaknesses' (list), and 'next_steps' (list).\"</p> <p>If you use our online platform to do this, then you'll need to retrieve your AI function: <pre><code>from aifn import AIFunction\nidea_evaluator = AIFunction(\"BusinessIdeaAnalyzer-XYZ123\"),  # Replace with your actual function name\nprint(f\"{idea_evaluator.fn_name}/{idea_evaluator.version}\")\n</code></pre></p> <p>Or, we can just stick to using Python to create our AI function: <pre><code>from aifn import build\nidea_evaluator = build(\n    task_description=\"Analyze a business idea and provide a well reasoned evaluation. Return 'viability_score' (0-100), 'strengths' (list), 'weaknesses' (list), and 'next_steps' (list).\",\n)\nprint(f\"{idea_evaluator.fn_name}/{idea_evaluator.version}\")\n</code></pre></p> <p>Now you can call your AI function, just like any other function, anywhere in your code! <pre><code>response = idea_evaluator(\"A subscription service for personalized, AI-generated bedtime stories for children.\")\n</code></pre></p> <p>To learn how to get the most your of your AI functions, check out our cookbook, our API reference and these end-to-end examples.</p> <p>Happy building!</p>"}]}